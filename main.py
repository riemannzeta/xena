# Xena Patent Analytics
# This is a Python script for ranking and valuing patents using per patent CSV data.
# Price estimates can be generated by assigning a $ per composite score coefficient. (See "coef" variable below.)
# Copyright 2023 Michael Frank Martin
# See LICENSE.md for license information.
import os
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt

# Color palette for plots
plt.style.use('seaborn')

# Configuration
# Declare file names of CSV benchmark set of patents and comparison set for comparison against benchmark
benchmark = '~/Downloads/benchmark_patent_data.csv'
comparison = '~/Downloads/comparison_patent_data.csv'
home = os.path.expanduser("~")

# File names used for export of CSV results
results = '~/Downloads/xena.csv'
not_scored = '~/Downloads/not_scored.csv'

# Set $ per composite score coefficient
# For purposes of demonstration, this is set to $1,000,000
# Thus, a "perfect" patent with a composite score of 1.0 would be worth $1,000,000
# In a real world application, the coefficient can be calculated as:
# sum of the composite scores for each patent in a portfolio (or portfolios) sold / sum paid for portfolio(s)
# The relevance of the coefficient (and hence, estimated valuations) is dependent upon (among other things):
# the similarity of the patents used to compute the coefficient and the patents being valued and
# the time elapsed since the patents used to compute the coefficient were sold.
# Choosing a benchmark portfolio that is similar to the comparison portfolio and that was sold recently allows
# calculation of a reasonable estimate of current market value.
coef = 1000000

# Helper functions
# Plot histograms
def plot_histogram(df, column):
    plt.hist(df[column], bins=100)
    plt.title(f'Histogram of {column}')
    plt.xlabel(f'{column}')
    plt.ylabel('Frequency')
    plt.savefig(home + f'/Downloads/{column}.png')
    plt.show()


# Prep date columns, including 'Days Since Priority' and 'Days to Expiration'
def prep_dates(df):
    # Identify data columns
    priority = 'Priority Date'
    expiry = 'Est. Expiration Date'
    dates = [priority, expiry]

    # Convert dataframe columns with date information from text to date type
    for i in range(len(dates)):
        modified_column = pd.to_datetime(df[dates[i]])
        df[dates[i]] = modified_column

    # Generate days since priority and days to expiration columns
    today = pd.Timestamp(datetime.now().date())
    df['Days Since Priority'] = (today - df[priority]).dt.days
    df['Days to Expiration'] = (df[expiry] - today).dt.days

    return df


# Compute composite score for each patent in a dataframe of patents
def compute_scores(df):
    # Filter out invalid data, including claims with zero word count and expired patents
    # Get the index of 'First Claim Word Count' rows with zero and non-zero values
    zero_value_indices = df[df['First Claim Word Count'] == 0].index
    non_zero_indices = df[df['First Claim Word Count'] != 0].index
    # Get the index of 'Days to Expiration' rows that are negative and non-negative
    expired_patents = df[df['Days to Expiration'] <= 0].index
    unexpired_patents = df[df['Days to Expiration'] > 0].index
    neither_expired_nor_invalid = non_zero_indices.intersection(unexpired_patents)

    # Calculate composite score, by calculating, for each patent, within a range normalized from zero to 1
    # 1. Forward citations divided by days since priority
    df['Impact'] = df['Number of Forward Citations'] / df['Days Since Priority']
    df['Normalized Impact'] = (df['Impact'] - df['Impact'].min()) / (df['Impact'].max() - df['Impact'].min())

    # 2. Inverse first claim word count, set rows with zero values to 'Invalid'
    df.loc[zero_value_indices, 'Scope'] = 'Invalid'
    df.loc[non_zero_indices, 'Scope'] = 1 / df.loc[non_zero_indices, 'First Claim Word Count']
    df.loc[zero_value_indices, 'Normalized Scope'] = 'Invalid'
    df.loc[non_zero_indices,'Normalized Scope'] = (df.loc[non_zero_indices, 'Scope'] - df.loc[non_zero_indices, 'Scope'].min()) / (df.loc[non_zero_indices, 'Scope'].max() - df.loc[non_zero_indices, 'Scope'].min())

    # 3. Days to expiration
    df.loc[expired_patents, 'Normalized Longevity'] = 'Expired'
    df.loc[unexpired_patents,'Normalized Longevity'] = (df.loc[unexpired_patents, 'Days to Expiration'] - df.loc[unexpired_patents, 'Days to Expiration'].min()) / (df.loc[unexpired_patents, 'Days to Expiration'].max() - df.loc[unexpired_patents, 'Days to Expiration'].min())

    # 4. Weights to use for Weighted sum of 1, 2, and 3:
    # Weights may be adjusted, but it's convenient to keep their sum equal to 1 so that the highest possible composite score possible is 1.
    # This allows one to eyeball whether a patent is "good" or "bad" by looking from its raw composite score, regardless of the coefficient used for pricing.
    impact = 0.65
    scope = 0.25
    longevity = 0.1

    # 5. Calculate 'Composite Score' with valid rows. Set invalid rows to 'Invalid' or 'Expired'
    df.loc[zero_value_indices, 'Composite Score'] = 'Invalid'
    df.loc[expired_patents, 'Composite Score'] = 'Expired'
    df.loc[neither_expired_nor_invalid, 'Composite Score'] = impact * df.loc[neither_expired_nor_invalid,'Normalized Impact'] + scope * df.loc[neither_expired_nor_invalid,'Normalized Scope'] + longevity * df.loc[neither_expired_nor_invalid,'Normalized Longevity']

    return df


# Coerce to numerical values of Composite Score only
def coerce_numerical(df):
    # Coerce non-numeric values to NaN and then filter out rows with only numeric values
    # Truncates rows without a valid Composite Score (e.g., expired patents)
    df['Composite Score'] = pd.to_numeric(df['Composite Score'], errors='coerce')
    df_numerical = df[df['Composite Score'].notna()]
    df_nan = df[df['Composite Score'].isna()]
    return [df_numerical, df_nan]


# Rank Composite Scores by percentile
def rank_by_percentile(df):
    arr = coerce_numerical(df)
    df = arr[0]
    df['Percentile'] = df['Composite Score'].rank(pct=True)
    return df


# Interpolate comparison portfolio percentiles from composite scores and benchmark portfolio percentiles
def interp_percentiles(bm, cp):
    # Coerce the comparison portfolio to only numerical valued Composite Scores
    # Benchmark portfolio was coerced to numerical in rank_by_percentile
    arr = coerce_numerical(cp)
    cp = arr[0]
    # Sort both bm and cp by Composite Score
    bm = bm.sort_values('Composite Score')
    cp = cp.sort_values('Composite Score')
    # Interpolate percentiles for the comparison portfolio using percentiles and composite scores from the benchmark portfolio
    cp['Percentile'] = np.interp(cp['Composite Score'], bm['Composite Score'], bm['Percentile'])
    return cp


# Main control flow
def xena():
    # Read the CSV files into dataframes and load dataframes into an array
    # benchmark and comparison CSV file names are declared at the top of this file
    bms = pd.read_csv(benchmark)
    cmp = pd.read_csv(comparison)
    dfs = [bms, cmp]

    # Declare and empty dataframe to catch invalid and expired patents without Composite Scores
    nans = pd.DataFrame()
    # For both benchmark and comparison sets:
    for i in range(len(dfs)):
        # Prepare date information for analysis
        dfs[i] = prep_dates(dfs[i])
        # Compute composite scores for each patent
        dfs[i] = compute_scores(dfs[i])
        # Coerce to numerical values and split into array of numerical and non-numerical Composite Scores
        arr = coerce_numerical(dfs[i])
        dfs[i] = arr[0]
        # Append non-numerical Composite Scores to nans for export
        nans = nans.append(arr[1])

    # Compare benchmark portfolio to comparison portfolio by:
    # 1. Ranking the benchmark portfolio by percentile
    # 2. Interpolating percentiles for the comparison portfolio using composite scores calculated for patents in both

    # Step 1: Rank the benchmark portfolio Composite Scores by percentile
    bms = rank_by_percentile(bms)
    # Step 2: Interpolate benchmark portfolio percentiles for the comparison portfolio using composite scores
    cmp = interp_percentiles(bms, cmp)
    # Step 3: Price patents in the benchmark portfolio using the coefficient and composite scores
    cmp['Price'] = coef * cmp['Composite Score']

    # Export results to output file name declared at the top of this script
    bms.to_csv('~/Downloads/benchmark.csv', index=False)
    cmp.to_csv(results, index=False)
    nans.to_csv(not_scored, index=False)
    print("Xena analysis complete!")

    # Plot histogram showing composite scores of both benchmark and comparison portfolio on same chart
    bins = np.linspace(0, 1, 100)
    plt.hist(cmp['Composite Score'], bins, label='Comparison', alpha=0.5)
    plt.hist(bms['Composite Score'], bins, label='Benchmark', alpha=0.5)
    plt.title(f'Histogram of Composite Scores')
    plt.xlabel('Composite Score')
    plt.ylabel('Frequency')
    plt.legend(loc='upper right')
    plt.savefig(home + '/Downloads/xena.png')
    plt.show()

    # Plot histograms of Normalized Impact, Normalized Scope, Normalized Longevity, and Percentile
    cols = ['Normalized Impact', 'Scope', 'Days to Expiration', 'Percentile']
    for col in cols:
        plot_histogram(cmp, col)

if __name__ == '__main__':
    xena()